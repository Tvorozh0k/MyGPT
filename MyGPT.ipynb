{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qgqxv1Y3Z9fw",
        "02uQkYWZEhGC",
        "e6QxhtvMydZY",
        "WZqCmC57cs7L",
        "4CX3kxh2gUFV",
        "tOxNTrdji8Ya"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPOd5OucQQIvyG1hPM38xP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f82093070ed146a7822c1ad7b55aa8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74c46940f1b04b839966cdca86486064",
              "IPY_MODEL_b1b491e303cc4655897b31e040c0d2cf",
              "IPY_MODEL_e9f3917db46a4d20b0c466cccb9ff0f3"
            ],
            "layout": "IPY_MODEL_3d391c6b99f04f08ae2a4f751f1ca843"
          }
        },
        "74c46940f1b04b839966cdca86486064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b654d5eacbe74ceb9594acab7fd31e08",
            "placeholder": "​",
            "style": "IPY_MODEL_bcdd3042ffc044998a223f81d1aaf505",
            "value": "config.json: 100%"
          }
        },
        "b1b491e303cc4655897b31e040c0d2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090ed53e2deb4843b0068d5329dfa138",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a53d3a47d376471bac03f7829157c26c",
            "value": 665
          }
        },
        "e9f3917db46a4d20b0c466cccb9ff0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73452db8a8eb4dc986166d4eabc3e370",
            "placeholder": "​",
            "style": "IPY_MODEL_b07d0191e9fd4d0e923e16969d8c9114",
            "value": " 665/665 [00:00&lt;00:00, 32.9kB/s]"
          }
        },
        "3d391c6b99f04f08ae2a4f751f1ca843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b654d5eacbe74ceb9594acab7fd31e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcdd3042ffc044998a223f81d1aaf505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090ed53e2deb4843b0068d5329dfa138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53d3a47d376471bac03f7829157c26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73452db8a8eb4dc986166d4eabc3e370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07d0191e9fd4d0e923e16969d8c9114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf0a6de4b654c55b3779e389a9f62f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d145907dfc04d71811f6526df8d6a72",
              "IPY_MODEL_cac5d7fa7c984f9cb3b6f9f6e21b2663",
              "IPY_MODEL_a81e98cb37794381808b907e594c8202"
            ],
            "layout": "IPY_MODEL_85c3232083fa4453ae24d4f5e40769fc"
          }
        },
        "1d145907dfc04d71811f6526df8d6a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674307aca9784d45a548afb6d23ec8ea",
            "placeholder": "​",
            "style": "IPY_MODEL_77bfa9b2020c4b5cbb32ee4c318f6188",
            "value": "model.safetensors: 100%"
          }
        },
        "cac5d7fa7c984f9cb3b6f9f6e21b2663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce304b1e3a148b2917d1343b6728d75",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e901103d3504844b2df83f12d846743",
            "value": 548105171
          }
        },
        "a81e98cb37794381808b907e594c8202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ad7b40685140dab8e92022cc5859b1",
            "placeholder": "​",
            "style": "IPY_MODEL_24015d1d5bd84f6c803123a46bccb021",
            "value": " 548M/548M [00:03&lt;00:00, 171MB/s]"
          }
        },
        "85c3232083fa4453ae24d4f5e40769fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674307aca9784d45a548afb6d23ec8ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77bfa9b2020c4b5cbb32ee4c318f6188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce304b1e3a148b2917d1343b6728d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e901103d3504844b2df83f12d846743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ad7b40685140dab8e92022cc5859b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24015d1d5bd84f6c803123a46bccb021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "038a85ca327a4dd78c494f859a3a78ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b80334fdb594412bf6b87923614670e",
              "IPY_MODEL_7c85159d2d1340ca861911c3d88c1445",
              "IPY_MODEL_467101c9c8c34b068e58bfb1068ac74a"
            ],
            "layout": "IPY_MODEL_4f58c57f8b22429bbabe5c89afab2275"
          }
        },
        "6b80334fdb594412bf6b87923614670e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3363b47a58874608bd671520d04861ec",
            "placeholder": "​",
            "style": "IPY_MODEL_323706e2ef4443a6b47e8c2287f719cb",
            "value": "generation_config.json: 100%"
          }
        },
        "7c85159d2d1340ca861911c3d88c1445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9546688a3d8c43c399a875c52b277520",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e0da7e8f58f46a88469491d51a7d63a",
            "value": 124
          }
        },
        "467101c9c8c34b068e58bfb1068ac74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddfba2083164122b52d68b26c7ecced",
            "placeholder": "​",
            "style": "IPY_MODEL_6d672d25cf2f45648518f28c929fea99",
            "value": " 124/124 [00:00&lt;00:00, 6.38kB/s]"
          }
        },
        "4f58c57f8b22429bbabe5c89afab2275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3363b47a58874608bd671520d04861ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323706e2ef4443a6b47e8c2287f719cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9546688a3d8c43c399a875c52b277520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0da7e8f58f46a88469491d51a7d63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ddfba2083164122b52d68b26c7ecced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d672d25cf2f45648518f28c929fea99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tvorozh0k/MyGPT/blob/main/MyGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подключение библиотек"
      ],
      "metadata": {
        "id": "KigzMZ_8NJA7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vjs3u1zp_h7b"
      },
      "outputs": [],
      "source": [
        "#@title Подключение библиотеки PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Работа с трансформерами из Hugging Face\n",
        "\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv0BA7ez5hxJ",
        "outputId": "5aabfe85-4430-426d-e79d-ba9c1d0cdf84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yVDxYjmH_7zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теория"
      ],
      "metadata": {
        "id": "bxG_4hrBZ7Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Архитектура GPT2"
      ],
      "metadata": {
        "id": "HVPA3vxgaTmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "checkpoint = 'gpt2'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706,
          "referenced_widgets": [
            "f82093070ed146a7822c1ad7b55aa8ff",
            "74c46940f1b04b839966cdca86486064",
            "b1b491e303cc4655897b31e040c0d2cf",
            "e9f3917db46a4d20b0c466cccb9ff0f3",
            "3d391c6b99f04f08ae2a4f751f1ca843",
            "b654d5eacbe74ceb9594acab7fd31e08",
            "bcdd3042ffc044998a223f81d1aaf505",
            "090ed53e2deb4843b0068d5329dfa138",
            "a53d3a47d376471bac03f7829157c26c",
            "73452db8a8eb4dc986166d4eabc3e370",
            "b07d0191e9fd4d0e923e16969d8c9114",
            "7bf0a6de4b654c55b3779e389a9f62f9",
            "1d145907dfc04d71811f6526df8d6a72",
            "cac5d7fa7c984f9cb3b6f9f6e21b2663",
            "a81e98cb37794381808b907e594c8202",
            "85c3232083fa4453ae24d4f5e40769fc",
            "674307aca9784d45a548afb6d23ec8ea",
            "77bfa9b2020c4b5cbb32ee4c318f6188",
            "bce304b1e3a148b2917d1343b6728d75",
            "7e901103d3504844b2df83f12d846743",
            "67ad7b40685140dab8e92022cc5859b1",
            "24015d1d5bd84f6c803123a46bccb021",
            "038a85ca327a4dd78c494f859a3a78ad",
            "6b80334fdb594412bf6b87923614670e",
            "7c85159d2d1340ca861911c3d88c1445",
            "467101c9c8c34b068e58bfb1068ac74a",
            "4f58c57f8b22429bbabe5c89afab2275",
            "3363b47a58874608bd671520d04861ec",
            "323706e2ef4443a6b47e8c2287f719cb",
            "9546688a3d8c43c399a875c52b277520",
            "3e0da7e8f58f46a88469491d51a7d63a",
            "4ddfba2083164122b52d68b26c7ecced",
            "6d672d25cf2f45648518f28c929fea99"
          ]
        },
        "id": "V3LpsrVCaanD",
        "outputId": "7f5bf84e-fb11-4a12-ce26-feeeb1895787"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f82093070ed146a7822c1ad7b55aa8ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bf0a6de4b654c55b3779e389a9f62f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "038a85ca327a4dd78c494f859a3a78ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2SdpaAttention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Как работает `Dropout`?\n",
        "\n",
        "На вход подается `tensor`. Слой `nn.Dropout(p)` проходится по всем элементам тензора и с вероятностью `p` обнуляет элементы. Все элементы, также, умножаются на значение $\\frac{1}{1-p}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "qgqxv1Y3Z9fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\begin{bmatrix}0.9225 & 1.3627 \\\\ 0.2685 & 1.1718\\end{bmatrix} \\to {\\text{nn.Dropout(0.2)}} \\to \\begin{bmatrix}0.9225 \\cdot \\frac{1}{1-0.2} & 0 \\\\ 0.2685 \\cdot \\frac{1}{1-0.2} & 1.1718 \\cdot \\frac{1}{1-0.2}\\end{bmatrix} = \\begin{bmatrix}1.1531 & 0 \\\\ 0.3357 & 1.4647\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "HehiSxaFbcWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему умножение происходит на $\\frac{1}{1-p}$? Пусть дан тензор размерности $n \\times m$, все элементы которого равны $v$. Тогда, сумма элементов тензора равна $nmv$. После применения `dropout` с параметром $p$ математическое ожидание суммы равно $(1-p)nmv$ (сумма оставшихся ненулевых элементов). Таким образом, мы потеряли в сумме, мы потеряли ненулевые значения, и теперь мы хотим их перераспределить так, чтобы сумма осталось примерно такой же. Для этого нужно все оставшиеся ненулевые элементы в тензоре умножить на $${\\frac{1}{1-p}}$$. Тогда сумма: $\\frac{1}{1-p}(1-p)nmv = nmv$."
      ],
      "metadata": {
        "id": "ITiYzu3Bc7Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Пример\n",
        "\n",
        "d = nn.Dropout(p=0.2)\n",
        "\n",
        "input_tensor = torch.randn(2, 2)\n",
        "\n",
        "print(f\"[BEFORE DROPOUT]:\")\n",
        "print(f\"input_tensor:\\n{input_tensor}\")\n",
        "\n",
        "print(f\"\\n[AFTER DROPOUT]:\")\n",
        "print(f\"input_tensor:\\n{d(input_tensor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5BqqpdBanrR",
        "outputId": "afa29211-4592-4ef3-91ff-6b98c5b3474d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BEFORE DROPOUT]:\n",
            "input_tensor:\n",
            "tensor([[0.9225, 1.3627],\n",
            "        [0.2685, 1.1718]])\n",
            "\n",
            "[AFTER DROPOUT]:\n",
            "input_tensor:\n",
            "tensor([[1.1531, 0.0000],\n",
            "        [0.3357, 1.4647]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Арифметические операции над тензорами высшего порядка"
      ],
      "metadata": {
        "id": "02uQkYWZEhGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Перемножение трехмерных тензоров"
      ],
      "metadata": {
        "id": "AVD560iRFuCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$A = \\begin{bmatrix}A_1 & A_2 & \\dots & A_n\\end{bmatrix}, \\;\\;B = \\begin{bmatrix}B_1 & B_2 & \\dots & B_n\\end{bmatrix} \\quad \\to \\quad C = AB = \\begin{bmatrix}A_1 \\cdot B_1 & A_2 \\cdot B_2 & \\dots & A_n \\cdot B_n\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "gub5Cu5bGqUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$A: (n, m, p), \\;\\; B: (n, p, s) \\to C = AB: (n, m, s)$$"
      ],
      "metadata": {
        "id": "DcUrHjubHcAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(5, (2, 2, 3))\n",
        "print(f\"a[2, 2, 3]:\\n{a}\\n\")\n",
        "\n",
        "b = torch.randint(5, (2, 3, 2))\n",
        "print(f\"b[2, 3, 2]:\\n{b}\\n\")\n",
        "\n",
        "c = a @ b\n",
        "print(f\"c[2, 2, 2]:\\n{c}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5xmRPqiElto",
        "outputId": "006ee8bd-726d-47f0-8374-4c68f78a28b5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a[2, 2, 3]:\n",
            "tensor([[[2, 2, 2],\n",
            "         [4, 4, 1]],\n",
            "\n",
            "        [[3, 3, 2],\n",
            "         [3, 3, 1]]])\n",
            "\n",
            "b[2, 3, 2]:\n",
            "tensor([[[1, 1],\n",
            "         [1, 2],\n",
            "         [1, 3]],\n",
            "\n",
            "        [[1, 1],\n",
            "         [2, 3],\n",
            "         [2, 4]]])\n",
            "\n",
            "c[2, 2, 2]:\n",
            "tensor([[[ 6, 12],\n",
            "         [ 9, 15]],\n",
            "\n",
            "        [[13, 20],\n",
            "         [11, 16]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Аналогично и с другими измерениями (4 и выше)"
      ],
      "metadata": {
        "id": "TJO0kkPioVHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Транспонирование тензоров"
      ],
      "metadata": {
        "id": "ATtHaM0GHzaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((1, 2, 3, 4))\n",
        "print(f\"Before: {a.shape}\")\n",
        "\n",
        "a = a.transpose(1, 2)\n",
        "print(f\"After: {a.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX2crVseIW3p",
        "outputId": "597f59a6-0216-4664-caab-7a2c8f34a487"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: torch.Size([1, 2, 3, 4])\n",
            "After: torch.Size([1, 3, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
        "\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "print(a.transpose(0, 1).shape)\n",
        "print(a.transpose(0, 1))\n",
        "\n",
        "print(a.transpose(0, 2).shape)\n",
        "print(a.transpose(0, 2))\n",
        "\n",
        "print(a.transpose(1, 2).shape)\n",
        "print(a.transpose(1, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCkzgDS3pG4V",
        "outputId": "188c66da-e362-47e7-9404-875a001165d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2, 2])\n",
            "tensor([[[ 1,  2],\n",
            "         [ 3,  4]],\n",
            "\n",
            "        [[ 5,  6],\n",
            "         [ 7,  8]],\n",
            "\n",
            "        [[ 9, 10],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 3, 2])\n",
            "tensor([[[ 1,  2],\n",
            "         [ 5,  6],\n",
            "         [ 9, 10]],\n",
            "\n",
            "        [[ 3,  4],\n",
            "         [ 7,  8],\n",
            "         [11, 12]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[ 1,  5,  9],\n",
            "         [ 3,  7, 11]],\n",
            "\n",
            "        [[ 2,  6, 10],\n",
            "         [ 4,  8, 12]]])\n",
            "torch.Size([3, 2, 2])\n",
            "tensor([[[ 1,  3],\n",
            "         [ 2,  4]],\n",
            "\n",
            "        [[ 5,  7],\n",
            "         [ 6,  8]],\n",
            "\n",
            "        [[ 9, 11],\n",
            "         [10, 12]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Как работает `scaled_dot_product_attention`?"
      ],
      "metadata": {
        "id": "e6QxhtvMydZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Генерируем случайные матрицы $Q$, $K$ и $V$ и маску $M$\n",
        "\n",
        "q = torch.randn((3, 2))\n",
        "k = torch.randn((3, 2))\n",
        "v = torch.randn((3, 2))\n",
        "\n",
        "m = torch.tril(torch.ones(3, 3))\n",
        "m = m.masked_fill(m==0, float('-inf')) - 1\n",
        "\n",
        "print(f\"q:\\n{q}\\n\")\n",
        "print(f\"k:\\n{k}\\n\")\n",
        "print(f\"v:\\n{v}\\n\")\n",
        "print(f\"m:\\n{m}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anTiGa89ylh_",
        "outputId": "ab607005-28e9-49ed-c15d-b1f282b03142"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q:\n",
            "tensor([[ 0.6891, -0.2827],\n",
            "        [ 1.8924, -0.3903],\n",
            "        [ 1.7954,  1.0172]])\n",
            "\n",
            "k:\n",
            "tensor([[ 1.0728,  1.2521],\n",
            "        [ 0.1752, -0.2029],\n",
            "        [-0.2853, -1.4800]])\n",
            "\n",
            "v:\n",
            "tensor([[ 0.4326, -1.5850],\n",
            "        [ 0.2770, -0.8679],\n",
            "        [ 1.2798, -1.3554]])\n",
            "\n",
            "m:\n",
            "tensor([[0., -inf, -inf],\n",
            "        [0., 0., -inf],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Собственная реализация\n",
        "\n",
        "out = q\n",
        "\n",
        "out @= k.T\n",
        "print(f\"QK^T:\\n{out}\")\n",
        "\n",
        "out *= 2 ** -0.5\n",
        "print(f\"QK^T / sqrt(d_k):\\n{out}\")\n",
        "\n",
        "out += m\n",
        "print(f\"QK^T / sqrt(d_k) + M:\\n{out}\")\n",
        "\n",
        "out = F.softmax(out, dim=-1)\n",
        "print(f\"Softmax(QK^T / sqrt(d_k) + M):\\n{out}\")\n",
        "\n",
        "out @= v\n",
        "print(f\"Softmax(QK^T / sqrt(d_k) + M) * V:\\n{out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2YUmEgczvQh",
        "outputId": "e03fcf8a-b6e8-4905-e889-147415f08c93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QK^T:\n",
            "tensor([[ 0.3853,  0.1781,  0.2218],\n",
            "        [ 1.5415,  0.4108,  0.0377],\n",
            "        [ 3.1996,  0.1082, -2.0177]])\n",
            "QK^T / sqrt(d_k):\n",
            "tensor([[ 0.2724,  0.1259,  0.1569],\n",
            "        [ 1.0900,  0.2904,  0.0267],\n",
            "        [ 2.2625,  0.0765, -1.4267]])\n",
            "QK^T / sqrt(d_k) + M:\n",
            "tensor([[ 0.2724,    -inf,    -inf],\n",
            "        [ 1.0900,  0.2904,    -inf],\n",
            "        [ 2.2625,  0.0765, -1.4267]])\n",
            "Softmax(QK^T / sqrt(d_k) + M):\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.6899, 0.3101, 0.0000],\n",
            "        [0.8792, 0.0988, 0.0220]])\n",
            "Softmax(QK^T / sqrt(d_k) + M) * V:\n",
            "tensor([[ 0.4326, -1.5850],\n",
            "        [ 0.3844, -1.3626],\n",
            "        [ 0.4359, -1.5091]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Готовый метод\n",
        "print(nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=m))\n",
        "print(nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True)) # передавать маску НЕ ОБЯЗАТЕЛЬНО"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-oZ3m6W1yAG",
        "outputId": "a656667a-9a50-4d7f-997b-dc13b2373c2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4326, -1.5850],\n",
            "        [ 0.3844, -1.3626],\n",
            "        [ 0.4359, -1.5091]])\n",
            "tensor([[ 0.4326, -1.5850],\n",
            "        [ 0.3844, -1.3626],\n",
            "        [ 0.4359, -1.5091]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Как работает `LayerNorm`?"
      ],
      "metadata": {
        "id": "WZqCmC57cs7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Генерация данных\n",
        "\n",
        "a = torch.randn((3, 4))\n",
        "\n",
        "print(f\"a:\\n{a}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ZdVVh9cxJi",
        "outputId": "e777ec64-907e-407f-96cd-623da8bbdacd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "tensor([[ 0.7600, -0.7958,  0.1175,  0.8433],\n",
            "        [-0.5222,  2.5007, -1.0763, -1.5622],\n",
            "        [-0.0441, -1.3374,  0.6868, -0.0910]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Собственная реализация\n",
        "\n",
        "print((a[0] - torch.mean(a[0])) / torch.sqrt(torch.var(a[0], correction=0) + 1e-05))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENA6qMXheeHr",
        "outputId": "1a9f500c-60d9-451d-efd3-a6c1ee079830"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.8058, -1.5653, -0.1734,  0.9329])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Готовый метод\n",
        "\n",
        "ln = nn.LayerNorm(4)\n",
        "\n",
        "print(f\"LayerNorm weights:\\n{ln.weight}\\n\")\n",
        "print(f\"LayerNorm bias:\\n{ln.bias}\\n\")\n",
        "\n",
        "print(f\"LayerNorm(x):\\n{ln(a)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY8kzxy_dyYD",
        "outputId": "6fd9b73d-3e1f-45ac-ed23-bf9c4a5c78f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LayerNorm weights:\n",
            "Parameter containing:\n",
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "\n",
            "LayerNorm bias:\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)\n",
            "\n",
            "LayerNorm(x):\n",
            "tensor([[ 0.8058, -1.5653, -0.1734,  0.9329],\n",
            "        [-0.2258,  1.6846, -0.5759, -0.8829],\n",
            "        [ 0.2094, -1.5686,  1.2143,  0.1449]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация классов"
      ],
      "metadata": {
        "id": "TW9Qak03NPmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. FFN (Feed Forward Network)"
      ],
      "metadata": {
        "id": "4CX3kxh2gUFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Размерности:**\n",
        "\n",
        "**[INPUT]: `(batch_size, sequence_length, n_embd)`**\n",
        "\n",
        "1. `c_fc`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, 4 * n_embd)`\n",
        "2. `gelu`: `(batch_size, sequence_length, 4 * n_embd)` $\\to$ `(batch_size, sequence_length, 4 * n_embd)`\n",
        "3. `c_proj`: `(batch_size, sequence_length, 4 * n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "4. `dropout`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "\n",
        "**[OUTPUT]: `(batch_size, sequence_length, n_embd)`**"
      ],
      "metadata": {
        "id": "tiyhyQRChxs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Реализация класса\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.gelu = nn.GELU(approximate='tanh')\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fT7EePo5NR8g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Пример работы\n",
        "\n",
        "class ExampleConfig:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_embd = 2\n",
        "\n",
        "\n",
        "config = ExampleConfig()\n",
        "ff_layer = FeedForward(config)\n",
        "\n",
        "input_tensor = torch.randn(config.n_embd)\n",
        "print(f\"Input tensor (x): {input_tensor}\")\n",
        "\n",
        "print(\"\\nFeed Forward [FIRST_STEP]:\\n\")\n",
        "\n",
        "# layer parameters\n",
        "print(f\"c_fc.weight:\\n{ff_layer.c_fc.weight}\")\n",
        "print(f\"c_fc.bias:\\n{ff_layer.c_fc.bias}\")\n",
        "\n",
        "# validation\n",
        "print(f\"[CLASS] x = c_fc(x): {ff_layer.c_fc(input_tensor)}\")\n",
        "print(f\"[CHECK]: xW^T + b = {input_tensor @ ff_layer.c_fc.weight.T + ff_layer.c_fc.bias}\")\n",
        "\n",
        "print(\"\\nFeed Forward [SECOND_STEP]:\\n\")\n",
        "\n",
        "# validation\n",
        "print(f\"[CLASS] x = GELU(c_fc(x)): {ff_layer.gelu(ff_layer.c_fc(input_tensor))}\")\n",
        "\n",
        "m = nn.GELU(approximate='tanh')\n",
        "print(f\"[CHECK]: x = GELU(xW^T + b) = {m(input_tensor @ ff_layer.c_fc.weight.T + ff_layer.c_fc.bias)}\")\n",
        "\n",
        "print(\"\\nFeed Forward [THIRD_STEP]:\\n\")\n",
        "\n",
        "# layer parameters\n",
        "print(f\"c_fc.weight:\\n{ff_layer.c_proj.weight}\")\n",
        "print(f\"c_fc.bias:\\n{ff_layer.c_proj.bias}\")\n",
        "\n",
        "# validation\n",
        "print(f\"[CLASS] x = c_proj(GELU(c_fc(x))): {ff_layer.c_proj(ff_layer.gelu(ff_layer.c_fc(input_tensor)))}\")\n",
        "print(f\"[CHECK]: GELU(xW^T + b)W^T + b = {m(input_tensor @ ff_layer.c_fc.weight.T + ff_layer.c_fc.bias) @ ff_layer.c_proj.weight.T + ff_layer.c_proj.bias}\")\n",
        "\n",
        "print(\"\\nFeed Forward [FOURTH_STEP, DROPOUT]:\\n\")\n",
        "print(f\"[CLASS] x = FeedForward(x): {ff_layer.forward(input_tensor)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhX0R24fTXsV",
        "outputId": "1e111c5a-a1b7-467a-8658-8699c675dcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tensor (x): tensor([-1.5839,  0.0219])\n",
            "\n",
            "Feed Forward [FIRST_STEP]:\n",
            "\n",
            "c_fc.weight:\n",
            "Parameter containing:\n",
            "tensor([[-0.5494,  0.1919],\n",
            "        [-0.5304, -0.4630],\n",
            "        [ 0.6974,  0.6517],\n",
            "        [-0.6406, -0.3088],\n",
            "        [ 0.2704,  0.4117],\n",
            "        [-0.5300, -0.2456],\n",
            "        [ 0.1082,  0.5320],\n",
            "        [ 0.6661,  0.2216]], requires_grad=True)\n",
            "c_fc.bias:\n",
            "Parameter containing:\n",
            "tensor([-0.6870,  0.5093, -0.4400,  0.3836, -0.6684, -0.0895,  0.2645, -0.6611],\n",
            "       requires_grad=True)\n",
            "[CLASS] x = c_fc(x): tensor([ 0.1875,  1.3393, -1.5304,  1.3914, -1.0877,  0.7446,  0.1048, -1.7112],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "[CHECK]: xW^T + b = tensor([ 0.1875,  1.3393, -1.5304,  1.3914, -1.0877,  0.7446,  0.1048, -1.7112],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Feed Forward [SECOND_STEP]:\n",
            "\n",
            "[CLASS] x = GELU(c_fc(x)): tensor([ 0.1077,  1.2182, -0.0966,  1.2770, -0.1507,  0.5746,  0.0568, -0.0746],\n",
            "       grad_fn=<GeluBackward0>)\n",
            "[CHECK]: x = GELU(xW^T + b) = tensor([ 0.1077,  1.2182, -0.0966,  1.2770, -0.1507,  0.5746,  0.0568, -0.0746],\n",
            "       grad_fn=<GeluBackward0>)\n",
            "\n",
            "Feed Forward [THIRD_STEP]:\n",
            "\n",
            "c_fc.weight:\n",
            "Parameter containing:\n",
            "tensor([[ 0.2393,  0.1246, -0.3221,  0.0010, -0.0766, -0.3419,  0.1319,  0.0828],\n",
            "        [ 0.2306, -0.0637, -0.0240, -0.0336, -0.1896,  0.0238, -0.1259, -0.0505]],\n",
            "       requires_grad=True)\n",
            "c_fc.bias:\n",
            "Parameter containing:\n",
            "tensor([ 0.0133, -0.1706], requires_grad=True)\n",
            "[CLASS] x = c_proj(GELU(c_fc(x))): tensor([ 0.0396, -0.2251], grad_fn=<ViewBackward0>)\n",
            "[CHECK]: GELU(xW^T + b)W^T + b = tensor([ 0.0396, -0.2251], grad_fn=<AddBackward0>)\n",
            "\n",
            "Feed Forward [FOURTH_STEP, DROPOUT]:\n",
            "\n",
            "[CLASS] x = FeedForward(x): tensor([ 0.0440, -0.2501], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. MultiHeadAttention"
      ],
      "metadata": {
        "id": "tOxNTrdji8Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Размерности:**\n",
        "\n",
        "**[INPUT]: `(batch_size, sequence_length, n_embd)`**\n",
        "\n",
        "1. `c_attn`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, 3 * n_embd)`\n",
        "2. **[SPLIT]**: `(batch_size, sequence_length, 3 * n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "3. **[HEADS]**: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, n_heads, head_size)`\n",
        "4. **[TRANSPOSE]**: `(batch_size, sequence_length, n_heads, head_size)` $\\to$ `(batch_size, n_heads, sequence_length, head_size)`\n",
        "5. **$Q \\cdot K^T$**: `(batch_size, n_heads, sequence_length, head_size)` $\\times$ `(batch_size, n_heads, head_size, sequence_length)` $\\to$ `(batch_size, n_heads, sequence_length, sequence_length)`\n",
        "6. **[SELF-ATTENTION]**: `(batch_size, n_heads, sequence_length, sequence_length)` $\\times$ `(batch_size, n_heads, sequence_length, head_size)` $\\to$ `(batch_size, n_heads, sequence_length, head_size)`\n",
        "7. **[TRANSPOSE]**: `(batch_size, n_heads, sequence_length, head_size)` $\\to$ `(batch_size, sequence_length, n_heads, head_size)`\n",
        "8. **[MERGE]**: `(batch_size, sequence_length, n_heads, head_size)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "9. `c_proj`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "**[OUTPUT]: `(batch_size, sequence_length, n_embd)`**"
      ],
      "metadata": {
        "id": "1pmdg8X62GIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Реализация класса\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # n_embd = n_heads * head_size\n",
        "        assert config.n_embd % config.n_heads == 0, \"Please, check the divisibility of n_embd by n_heads\"\n",
        "\n",
        "        # c_attn = [w_k | w_q | w_v] (concatenated)\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(p=0.1)\n",
        "        self.resid_dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        # n_heads, head_size\n",
        "        self.NH = config.n_heads\n",
        "        self.HS = config.n_embd // config.n_heads\n",
        "\n",
        "    def forward(self, x):\n",
        "        # batch_size, sequence_length, n_embd\n",
        "        BS, SL, EMB = x.shape\n",
        "\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(EMB, dim=2)\n",
        "\n",
        "        q = q.view(BS, SL, self.NH, self.HS).transpose(1, 2)\n",
        "        k = k.view(BS, SL, self.NH, self.HS).transpose(1, 2)\n",
        "        v = v.view(BS, SL, self.NH, self.HS).transpose(1, 2)\n",
        "\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "        y = self.attn_dropout(y)\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(BS, SL, EMB)\n",
        "\n",
        "        y = self.c_proj(y)\n",
        "        y = self.resid_dropout(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "1b-3JVajuT2l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Пример\n",
        "\n",
        "class ExampleConfig:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_embd = 8\n",
        "        self.n_heads = 2\n",
        "\n",
        "\n",
        "config = ExampleConfig()\n",
        "m = MultiHeadAttention(config)\n",
        "\n",
        "x = torch.randn((3, 4, 8))\n",
        "print(m(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2D69Id0qF1",
        "outputId": "8fec4f1e-961c-4226-d9e2-debbf0ab7722"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Block"
      ],
      "metadata": {
        "id": "Wo4flVuqco87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Размерности:**\n",
        "\n",
        "**[INPUT]: `(batch_size, sequence_length, n_embd)`**\n",
        "\n",
        "1. `attn`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "2. `mlp`: `(batch_size, sequence_length, n_embd)` $\\to$ `(batch_size, sequence_length, n_embd)`\n",
        "\n",
        "**[OUTPUT]: `(batch_size, sequence_length, n_embd)`**"
      ],
      "metadata": {
        "id": "9_LfUkM0h8rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Реализация класса\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = FeedForward(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual connection\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "s2aKDNiocqg6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Пример\n",
        "\n",
        "class ExampleConfig:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_embd = 8\n",
        "        self.n_heads = 2\n",
        "\n",
        "\n",
        "config = ExampleConfig()\n",
        "bl = Block(config)\n",
        "\n",
        "x = torch.randn((3, 4, 8))\n",
        "print(bl(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lidQyA6ciSoz",
        "outputId": "88df957d-6c9f-4b37-df90-9dcb8ae73e49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. MyGPT"
      ],
      "metadata": {
        "id": "9P9AYJrRiflb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Реализация класса\n",
        "\n",
        "class MyGPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(n_layers)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd)\n",
        "        ))\n",
        "\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        # weight sharing scheme\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        def forward(self, idx, targets=None):\n",
        "            BS, SL = idx.shape\n",
        "\n",
        "            assert SL <= config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "\n",
        "            tok_emb = self.transformer.wte(idx)\n",
        "\n",
        "            pos = torch.arange(0, SL, dtype=torch.long)\n",
        "            pos_emb = self.transformer.wpe(pos)\n",
        "\n",
        "            x = tok_emb + pos_emb\n",
        "\n",
        "            for block in self.transformer.h:\n",
        "                x = block(x)\n",
        "\n",
        "            x = self.transformer.ln_f(x)\n",
        "            logits = self.lm_head(x)\n",
        "\n",
        "            loss = None\n",
        "\n",
        "            if targets is not None:\n",
        "                loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "            return logits, loss"
      ],
      "metadata": {
        "id": "HvFB8m__iqKW"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}